{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "359d3f0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1389850774.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Amar Deep\\AppData\\Local\\Temp\\ipykernel_19888\\1389850774.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    import pandas as pd>\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd>\n",
    "import numpy as np\n",
    "import warnings   \n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "import seaborn as sns \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545b96b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19888\\72129270.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#path_port = \"archive/House_Rent_Dataset.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"housing.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#path_port = \"archive/House_Rent_Dataset.csv\"\n",
    "data = pd.read_csv(\"housing.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c2505",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8966d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the column names of the dataframe\n",
    "\n",
    "col_names = data.columns\n",
    "\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e6a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that there are leading spaces (spaces at the start of the string name) in the dataframe. So, I will remove these leading spaces.\n",
    "\n",
    "# remove leading spaces from column names\n",
    "\n",
    "data.columns = data.columns.str.strip()\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09dd6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution of target_class column\n",
    "\n",
    "data['total_rooms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef0591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the percentage distribution of target_class column\n",
    "\n",
    "data['total_rooms'].value_counts()/np.float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0027a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that percentage of observations of the class label 0 and 1 is 90.84% and 9.16%. So, this is a class imbalanced problem. I will deal with that in later section.\n",
    "\n",
    "# view summary of dataset\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in variables\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5461a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values in a column with the mean\n",
    "data['total_bedrooms'] = data['total_bedrooms'].fillna(data['total_bedrooms'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc77fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outliers in numerical variables\n",
    "\n",
    "\n",
    "# view summary statistics in numerical variables\n",
    "\n",
    "round(data.describe(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68469d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On closer inspection, we can suspect that all the continuous variables may contain outliers.\n",
    "\n",
    "# I will draw boxplots to visualise outliers in the above variables.\n",
    "\n",
    "# draw boxplots to visualize outliers\n",
    "\n",
    "plt.figure(figsize=(24,20))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "fig = data.boxplot(column='longitude')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('longitude')\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "fig = data.boxplot(column='median_house_value')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('median_house_value')\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "fig = data.boxplot(column='latitude')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('latitude')\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "fig = data.boxplot(column='total_bedrooms')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('total_bedrooms')\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "fig = data.boxplot(column='housing_median_age')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('housing_median_age')\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 5)\n",
    "fig = data.boxplot(column='median_income')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('median_income')\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 6)\n",
    "fig = data.boxplot(column='households')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('households')\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 7)\n",
    "fig = data.boxplot(column='population')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('population')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b81ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of variables\n",
    "# Now, I will plot the histograms to check distributions to find out if they are normal or skewed.\n",
    "\n",
    "# plot histogram to check distribution\n",
    "\n",
    "\n",
    "plt.figure(figsize=(24,20))\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "fig = data['latitude'].hist(bins=20)\n",
    "fig.set_xlabel('latitude')\n",
    "fig.set_ylabel('Number of pulsar stars')\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "fig = data['median_house_value'].hist(bins=20)\n",
    "fig.set_xlabel('median_house_value')\n",
    "fig.set_ylabel('Number of pulsar stars')\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "fig = data['median_income'].hist(bins=20)\n",
    "fig.set_xlabel('median_income')\n",
    "fig.set_ylabel('Number of pulsar stars')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "fig = data['households'].hist(bins=20)\n",
    "fig.set_xlabel('households')\n",
    "fig.set_ylabel('Number of pulsar stars')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 5)\n",
    "fig = data['population'].hist(bins=20)\n",
    "fig.set_xlabel('population')\n",
    "fig.set_ylabel('Number of pulsar stars')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 6)\n",
    "fig = data['total_bedrooms'].hist(bins=20)\n",
    "fig.set_xlabel('total_bedrooms')\n",
    "fig.set_ylabel('Number of pulsar stars')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(4, 2, 7)\n",
    "fig = data['housing_median_age'].hist(bins=20)\n",
    "fig.set_xlabel('housing_median_age')\n",
    "fig.set_ylabel('Number of pulsar stars')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25b8029",
   "metadata": {},
   "source": [
    "### 9. Declare feature vector and target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['total_rooms'], axis=1)\n",
    "\n",
    "y = data['total_rooms']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0b0662",
   "metadata": {},
   "source": [
    "### 10. Split data into separate training and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd7dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of X_train and X_test\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684d82f5",
   "metadata": {},
   "source": [
    "### 11. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f48a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test, columns=[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089a342",
   "metadata": {},
   "source": [
    "### 12. Run SVM with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7142bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default hyperparameter means C=1.0, kernel=rbf and gamma=auto among other parameters.\n",
    "\n",
    "# import SVC classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# import metrics to compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# instantiate classifier with default hyperparameters\n",
    "svc=SVC() \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_test)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ee68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVM with rbf kernel and C=100.0\n",
    "# We have seen that there are outliers in our dataset. So, we should increase the value of C as higher C means fewer outliers. So, I will run SVM with kernel=rbf and C=100.0.\n",
    "\n",
    "# instantiate classifier with rbf kernel and C=100\n",
    "svc=SVC(C=100.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_test)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVM with rbf kernel and C=1000.0\n",
    "# instantiate classifier with rbf kernel and C=1000\n",
    "svc=SVC(C=1000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_test)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with rbf kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f851c6b3",
   "metadata": {},
   "source": [
    "### 13. Run SVM with linear kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed764b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVM with linear kernel and C=1.0\n",
    "# instantiate classifier with linear kernel and C=1.0\n",
    "linear_svc=SVC(kernel='linear', C=1.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "linear_svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred_test=linear_svc.predict(X_test)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc1b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVM with linear kernel and C=100.0\n",
    "# instantiate classifier with linear kernel and C=100.0\n",
    "linear_svc100=SVC(kernel='linear', C=100.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "linear_svc100.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=linear_svc100.predict(X_test)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87660118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVM with linear kernel and C=1000.0\n",
    "# instantiate classifier with linear kernel and C=1000.0\n",
    "linear_svc1000=SVC(kernel='linear', C=1000.0) \n",
    "\n",
    "\n",
    "# fit classifier to training set\n",
    "linear_svc1000.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=linear_svc1000.predict(X_test)\n",
    "\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aada3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the train-set and test-set accuracy\n",
    "# Now, I will compare the train-set and test-set accuracy to check for overfitting.\n",
    "\n",
    "y_pred_train = linear_svc.predict(X_train)\n",
    "\n",
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13bf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d57323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overfitting and underfitting\n",
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(linear_svc.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(linear_svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff400935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
